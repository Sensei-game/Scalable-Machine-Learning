{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2c5fcec",
   "metadata": {},
   "source": [
    "A.\tPerform a five-fold cross validation of ALS-based recommendation on the rating data ratings.csv with two versions of ALS to compare: one with the ALS setting used in Lab 7 notebook, and another different setting decided by you with a brief explanation of why. \n",
    "\n",
    "For each split, find the top 10% users in the training set who have rated the most movies, calling them as HotUsers, and the bottom 10% users who have rated the least movies (but rated at least one movie), calling them CoolUsers. \n",
    "\n",
    "Compute the Root Mean Square Error (RMSE) on the test set for the HotUsers and CoolUsers separately, for each of the three splits and each ALS version. Put these RMSE results in one Table in the report (2 versions x 5 splits x 2 user groups = 20 numbers in total). Visualise these 20 numbers in ONE single figure. [6 marks]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cd77b3",
   "metadata": {},
   "source": [
    "B.\tAfter ALS, each movie is modelled with some factors. Use k-means with k=10 to cluster the movie factors (hint: see itemFactors in ALS API) learned with the ALS setting in Lab 7 notebook in A for each of the five splits. Note that each movie is associated with several tags.\n",
    "\n",
    "For each of the five splits, use genome-scores.csv to find the top tag (with the most movies) and bottom tag (with the least movies, if there are ties, randomly pick one from them) for the top two largest clusters (i.e., 4 tags in total for each split), find out the names of these top/bottom tags using genome-tags.csv. \n",
    "\n",
    "For each cluster and each split, report the two tags (one top one bottom) in one table (so 2 clusters x 5 splits x 2 tags = 20 tags to report in total). Hint: For each cluster, sum up tag scores for all movies in it; find the largest/smallest scores and their indexes; go to genome-tags to find their names (not manually but writing code to do so).\n",
    "\n",
    "You can use any information provided by the dataset to answer the question. [6 marks]\n",
    "\n",
    "\n",
    "C.\tDiscuss two most interesting observations from A & B above, each with three sentences: 1) What is the observation? 2) What are the possible causes of the observation? 3) How useful is this observation to a movie website such as Netflix? [2 marks]\n",
    "D.\t    Your report must be clearly written and your code must be well documented so that it is clear what each step is doing. [1 mark]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d1cca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "spark = SparkSession.Builder().master(\"local[6]\").appName(\"Scalab_Q2_Part2\").config(\"spark.local.dir\",\"C:\\temp\").getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4500169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "matplotlib.use('Agg') # Must be before importing matplotlib.pyplot or pylab! \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18115f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "ratFile = spark.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferSchema\", \"true\")\\\n",
    "    .csv(\"ml-25m/ratings.csv\").cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b4fe94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ratFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f98834a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000095"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratFile.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a2d9d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratFile.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "750f78d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "HotUsersdf = (ratFile.groupBy(\"userId\")\n",
    "                      .count()\n",
    "                      .sort(\"count\", ascending=False)\n",
    "                      .select(col(\"userId\"), \n",
    "                              col(\"count\").alias(\"most reviewed\")))\n",
    "\n",
    "ColdUsersdf = (ratFile.groupBy(\"userId\")\n",
    "                      .count()\n",
    "                      .sort(\"count\", ascending=True)\n",
    "                      .select(col(\"userId\"), \n",
    "                              col(\"count\").alias(\"Least reviewed\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a771a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162541\n",
      "16254\n",
      "+------+-------------+\n",
      "|userId|most reviewed|\n",
      "+------+-------------+\n",
      "|72315 |32202        |\n",
      "|80974 |9178         |\n",
      "|137293|8913         |\n",
      "|33844 |7919         |\n",
      "|20055 |7488         |\n",
      "|109731|6647         |\n",
      "|92046 |6564         |\n",
      "|49403 |6553         |\n",
      "|30879 |5693         |\n",
      "|115102|5649         |\n",
      "|110971|5633         |\n",
      "|75309 |5525         |\n",
      "|78849 |5276         |\n",
      "|61010 |5244         |\n",
      "|29803 |5219         |\n",
      "|122011|5160         |\n",
      "|57548 |5066         |\n",
      "|93855 |5045         |\n",
      "|103611|4861         |\n",
      "|34987 |4831         |\n",
      "|162047|4780         |\n",
      "|136310|4764         |\n",
      "|36618 |4710         |\n",
      "|8619  |4689         |\n",
      "|143049|4663         |\n",
      "|132651|4578         |\n",
      "|17783 |4569         |\n",
      "|97452 |4553         |\n",
      "|85757 |4505         |\n",
      "|162516|4489         |\n",
      "+------+-------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16254"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HotUsersdf.cache()\n",
    "\n",
    "# HotUsersdf.show(30,truncate=False)\n",
    "\n",
    "\n",
    "print(HotUsersdf.count())\n",
    "\n",
    "print(int(HotUsersdf.count()*0.1))\n",
    "\n",
    "HotUsersdf= HotUsersdf.limit(int(HotUsersdf.count()*0.1))\n",
    "\n",
    "\n",
    "\n",
    "HotUsersdf.show(30,truncate=False)\n",
    "\n",
    "HotUsersdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "105e61f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162541\n",
      "16254\n",
      "+------+--------------+\n",
      "|userId|Least reviewed|\n",
      "+------+--------------+\n",
      "|4101  |20            |\n",
      "|8389  |20            |\n",
      "|31367 |20            |\n",
      "|31951 |20            |\n",
      "|59355 |20            |\n",
      "|69478 |20            |\n",
      "|70355 |20            |\n",
      "|81501 |20            |\n",
      "|96261 |20            |\n",
      "|97186 |20            |\n",
      "|99168 |20            |\n",
      "|103357|20            |\n",
      "|108460|20            |\n",
      "|111300|20            |\n",
      "|120706|20            |\n",
      "|134924|20            |\n",
      "|150300|20            |\n",
      "|8928  |20            |\n",
      "|19200 |20            |\n",
      "|38707 |20            |\n",
      "|60835 |20            |\n",
      "|61766 |20            |\n",
      "|62880 |20            |\n",
      "|71709 |20            |\n",
      "|72546 |20            |\n",
      "|76169 |20            |\n",
      "|83769 |20            |\n",
      "|86400 |20            |\n",
      "|93691 |20            |\n",
      "|100615|20            |\n",
      "+------+--------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16254"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ColdUsersdf.cache()\n",
    "\n",
    "# ColdUsersdf.show(30,truncate=False)\n",
    "\n",
    "\n",
    "print(ColdUsersdf.count())\n",
    "\n",
    "print(int(ColdUsersdf.count()*0.1))\n",
    "\n",
    "ColdUsersdf= ColdUsersdf.limit(int(ColdUsersdf.count()*0.1))\n",
    "\n",
    "\n",
    "\n",
    "ColdUsersdf.show(30,truncate=False)\n",
    "\n",
    "ColdUsersdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a76e57d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "myseed=8744\n",
    "(training, test) = ratFile.randomSplit([0.8, 0.2], myseed) #Inlocuieste cu 0.2, 0.2, 0.2, 0.2,0.2\n",
    "training = training.cache()\n",
    "test = test.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a87aab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "# from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "als = ALS(userCol=\"userId\", itemCol=\"movieId\", seed=myseed, coldStartStrategy=\"drop\")\n",
    "\n",
    "als2 = ALS(rank=10,userCol=\"userId\", itemCol=\"movieId\", seed=myseed, coldStartStrategy=\"drop\")\n",
    "\n",
    "#rank: the number of latent factors in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efef084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test ALS fitting and transforming...\")\n",
    "\n",
    "model = als.fit(training)\n",
    "\n",
    "predictions = model.transform(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eda367",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Test ALS Root-mean-square-error = \" + str(rmse))\n",
    "# Root-mean-square error = 0.920957307650525"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "216730ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    " \n",
    "np.random.seed(8744)\n",
    "# create the range 1 to 25\n",
    "rn = range(1,20)   \n",
    "    \n",
    "kf5 = KFold(n_splits=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce5696a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] [1 2 3 4]\n",
      "[ 1  2  3  4  9 10 11 12 13 14 15 16 17 18 19] [5 6 7 8]\n",
      "[ 1  2  3  4  5  6  7  8 13 14 15 16 17 18 19] [ 9 10 11 12]\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 17 18 19] [13 14 15 16]\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16] [17 18 19]\n"
     ]
    }
   ],
   "source": [
    "# to get the values from our data, we use np.take() to access a value at particular index\n",
    "for train_index, test_index in kf5.split(rn):\n",
    "    print(np.take(rn,train_index), np.take(rn,test_index))\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e85eece1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected sequence or array-like, got <class 'pyspark.sql.dataframe.DataFrame'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-b45a239687f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkf5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mratFile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mratFile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtesting\u001b[0m \u001b[0mset\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthat\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \"\"\"\n\u001b[1;32m--> 324\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    297\u001b[0m     \"\"\"\n\u001b[0;32m    298\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    257\u001b[0m     \"\"\"\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    257\u001b[0m     \"\"\"\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    196\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected sequence or array-like, got <class 'pyspark.sql.dataframe.DataFrame'>"
     ]
    }
   ],
   "source": [
    "# Nope\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in kf5.split(ratFile):\n",
    "    X_train = ratFile.iloc[train_index].loc[:, features]\n",
    "    X_test = ratFile.iloc[test_index][features]\n",
    "    \n",
    "    #Train the model\n",
    "    fold_model = als.fit(X_train, y_train) #Training the model\n",
    "    print(f\"Accuracy for the fold no. {i} on the test set: {accuracy_score(y_test, model.predict(X_test))}\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6941cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use LOOCV to evaluate model\n",
    "# scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error',\n",
    "#                          cv=cv, n_jobs=-1)\n",
    "\n",
    "#view RMSE\n",
    "# sqrt(mean(absolute(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd827f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  NU E NeVOIE\n",
    "# cv = CrossValidator(estimator=als, evaluator=evaluator, numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30eb672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit cross validator to the 'train' dataset\n",
    "\n",
    "# model = cv.fit(train)#Extract best model from the cv model above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4877fb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = model.bestModel# View the predictions\n",
    "\n",
    "# test_predictions = best_model.transform(test)\n",
    "\n",
    "# RMSE = evaluator.evaluate(test_predictions)\n",
    "\n",
    "# print(RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728de0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate n Recommendations for all users\n",
    "# recommendations = best_model.recommendForAllUsers(5)\n",
    "# recommendations.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3f2265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movies = ratFile.select(als.getItemCol()).distinct().limit(3)\n",
    "\n",
    "# movieSubSetRecs = model.recommendForItemSubset(movies, 10)\n",
    "\n",
    "# movies.show()\n",
    "# +-------+\n",
    "# |movieId|\n",
    "# +-------+\n",
    "# |    474|\n",
    "# |     29|\n",
    "# |     26|\n",
    "# +-------+\n",
    "# movieSubSetRecs.show(3,False)\n",
    "# 20*5\n",
    "\n",
    "for loop i k=5\n",
    "    test set \n",
    "    trainning set unions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9710e9",
   "metadata": {},
   "source": [
    "A.\tPerform a five-fold cross validation of ALS-based recommendation on the rating data ratings.csv with two versions of ALS to compare: one with the ALS setting used in Lab 7 notebook, and another different setting decided by you with a brief explanation of why.\n",
    "\n",
    "For each split, find the top 10% users in the training set who have rated the most movies, calling them as HotUsers, and the bottom 10% users in the training set who have rated the least movies (but rated at least one movie), calling them CoolUsers. \n",
    "\n",
    "Compute the Root Mean Square Error (RMSE) on the test set for the HotUsers and CoolUsers separately, for each of the FIVE splits and each ALS version. \n",
    "\n",
    " Put these RMSE results in one Table in the report (2 versions x 5 splits x 2 user groups = 20 numbers in total). Visualise these 20 numbers in ONE single figure. [6 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc15e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# five-fold cross validation \n",
    "\n",
    "#ALS lab 7\n",
    "\n",
    "#ALS mine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca815a9",
   "metadata": {},
   "source": [
    "B.\tAfter ALS, each movie is modelled with some factors. Use k-means with k=10 to cluster the movie factors (hint: see itemFactors in ALS API) learned with the ALS setting in Lab 7 notebook in A for each of the five splits. \n",
    "\n",
    "Note that each movie is associated with several tags. \n",
    "\n",
    "For each of the five splits, find the top tag (with the most movies) and bottom tag (with the least movies, if there are ties, randomly pick one from them) for the top two largest clusters (i.e., 4 tags in total for each split).\n",
    "\n",
    "For each cluster and each split, report the two tags (one top one bottom) in one table (so 2 clusters x 5 splits x 2 tags = 20 tags to report in total). You can use any information provided by the dataset to answer the question. [6 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0386b59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
